{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 images are extacted in test.\n"
     ]
    }
   ],
   "source": [
    "folder = 'test'  \n",
    "os.mkdir(folder)\n",
    "vidcap = cv2.VideoCapture (\"sample_video.mp4\")\n",
    "success, image = vidcap.read()\n",
    "count=0;\n",
    "success = True\n",
    "while success:\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cv2.imwrite(os.path.join(folder,\"frame{:d}.jpg\".format(count)), image)\n",
    "                    #read the image \"frame{:d}.jpg\" = y0\n",
    "                    #find the max, y%d = np.max(frame%d[10:10,20:20,0:2])\n",
    "    count +=1\n",
    "print(\"{} images are extacted in {}.\".format(count,folder)) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-1ce6be1829d0>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-1ce6be1829d0>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    print(int g.shape)\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "filenames = [img for img in glob.glob(\"test/*.jpg\")]\n",
    "\n",
    "filenames.sort() # ADD THIS LINE\n",
    "\n",
    "test = []\n",
    "for img in filenames:\n",
    "    n= cv2.imread(img)\n",
    "    test.append(n)\n",
    "    #print (img)\n",
    "    g = ('test\\frame0.jpg')\n",
    "    print(int g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 images are extacted in test.\n"
     ]
    }
   ],
   "source": [
    "folder = 'test'  \n",
    "os.mkdir(folder)\n",
    "vidcap = cv2.VideoCapture (\"sample_video.mp4\")\n",
    "success, image = vidcap.read()\n",
    "count=0;\n",
    "success = True\n",
    "while success:\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cv2.imwrite(os.path.join(folder,\"frame{:d}.jpg\".format(count)), image)\n",
    "    #cv2.imread(os.path.join(folder,\"frame{:d}.jpg\".format(count)), image)\n",
    "    count +=1\n",
    "print(\"{} images are extacted in {}.\".format(count,folder)) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = 'test'  \n",
    "os.mkdir(folder)\n",
    "vidcap = cv2.VideoCapture (\"sample_video.mp4\")\n",
    "success, image = vidcap.read()\n",
    "count=0;\n",
    "success = True\n",
    "while success:\n",
    "    success, image = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cv2.imwrite(os.path.join(folder,\"frame{:d}.jpg\".format(count)), image)\n",
    "    y%d = np.max(frame%d[10:10,20:20,0:2]) #(error here) meant to read a square section on each frame and find its max pixel value\n",
    "    count +=1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second using video.get(cv2.CAP_PROP_FPS) : 15.0\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__' :\n",
    " \n",
    "    video = cv2.VideoCapture(\"sample_video.mp4\");\n",
    "     \n",
    "    # Find OpenCV version\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "     \n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "        print ('Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}'.format(fps))\n",
    "    else :\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        print ('Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}'.format(fps))\n",
    "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print( length )\n",
    "    video.release(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-67db984cd3ab>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-67db984cd3ab>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    img = cv2.imread(file) for file in glob.glob(\"C:\\Users\\Tom\\Documents\\Project 1\\Project1\\test\\frame0.jpg\")\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(file) for file in glob.glob(\"C:\\Users\\Tom\\Documents\\Project 1\\Project1\\test\\frame0.jpg\")\n",
    "    y = np.mean(img[10:10,20:20,0:2])\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-37-534e26105873>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-534e26105873>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    mypath='C:\\Users\\Tom\\Documents\\Project 1\\Project1\\test'\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "mypath='C:\\Users\\Tom\\Documents\\Project 1\\Project1\\test'\n",
    "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "img = numpy.empty(len(onlyfiles), dtype=object)\n",
    "for n in range(0, len(onlyfiles)):\n",
    "    img[n] = cv2.imread( join(mypath,onlyfiles[n]) )\n",
    "    \n",
    "    #y = np.mean(img[10:10,20:20,0:2])\n",
    "    #print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture (\"sample_video.mp4\")\n",
    "success, image = vidcap.read()\n",
    "\n",
    "#vidcap = cv2.videocapture(0)\n",
    "#size = Resizeutils.cvResizecapture (vidcap,imagesize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a new frame:  True\n"
     ]
    }
   ],
   "source": [
    "count=0;\n",
    "success = True\n",
    "while success:\n",
    "    success, image = vidcap.read()\n",
    "    cv2.imwrite(\"frame%d.jpg\" % count, image)\n",
    "    #y%d = np.mean(img[a1:a2,b1:b2,c1:c2])    #confirm y%d\n",
    "    #if cv2.waitKey(10) ==27;   #might not be needed    \n",
    "    print('Read a new frame: ', success)\n",
    "    break\n",
    "    count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = [y0,y1,y2,y3,y4,y5,y6,y7,y8,y9,y10,y11,y12,y13,y14,y15,y16,y17,y18,y19,\n",
    "     y20,y21,y22,y23,y24,y25,y26,y27,y28,y29,y30,y31,y32,y33,y34,y35,y36,y37,y38,y39,\n",
    "     y40,y41,y42,y43,y44,y45,y46,y47,y48,y49,y50,y51,y52,y53,y54,y55,y56,y57,y58,y59,\n",
    "     y60,y61,y62,y63,y64,y65,y66,y67,y68,y69,y70,y71,y72,y73,y74,y75,y76,y77,y78,y79,\n",
    "     y80,y81,y82,y83,y84,y85,y86,y87,y88,y89]\n",
    "\n",
    "# K = [y0,y1,y2,y3,y4,y5,y6,y7,y8,y9,y10,y11,y12,y13,y14,y15,y16,y17,y18,y19,y20,y21,y22,y23,y24,y25,y26,y27,y28,y29,y30,y31,y32,y33,y34,y35,y36,y37,y38,y39,y40,y41,y42,y43,y44,y45,y46,y47,y48,y49,y50,y51,y52,y53,y54,y55,y56,y57,y58,y59,y60,y61,y62,y63,y64,y65,y66,y67,y68,y69,y70,y71,y72,y73,y74,y75,y76,y77,y78,y79,y80,y81,y82,y83,y84,y85,y86,y87,y88,y89,y90,y91,y92,y93,y94,y95,y96,y97,y98,y99,y100,y101,y102,y103,y104,y105,y106,y107,y108,y109,y110,y111,y112,y113,y114,y115,y116,y117,y118,y119,y120,y121,y122,y123,y124,y125,y126,y127,y128,y129,y130,y131,y132,y133,y134,y135,y136,y137,y138,y139,y140,y141,y142,y143,y144,y145,y146,y147,y148,y149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.min[K]\n",
    "w = np.max[K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = ((w-v)/2)+v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# R = [T:T:90]  #need to confirm the right code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# E = K-R #put graph on x-axis\n",
    " E = [y0 -T,y1 -T,y2 -T,y3 -T,y4 -T,y5 -T,y6 -T,y7 -T,y8 -T,y9 -T,\n",
    "      y10 -T,y11 -T,y12 -T,y13 -T,y14 -T,y15 -T,y16 -T,y17 -T,y18 -T,y19 -T,\n",
    "      y20 -T,y21 -T,y22 -T,y23 -T,y24 -T,y25 -T,y26 -T,y27 -T,y28 -T,y29 -T,\n",
    "      y30 -T,y31 -T,y32 -T,y33 -T,y34 -T,y35 -T,y36 -T,y37 -T,y38 -T,y39 -T,\n",
    "      y40 -T,y41 -T,y42 -T,y43 -T,y44 -T,y45 -T,y46 -T,y47 -T,y48 -T,y49 -T,\n",
    "      y50 -T,y51 -T,y52 -T,y53 -T,y54 -T,y55 -T,y56 -T,y57 -T,y58 -T,y59 -T,\n",
    "      y60 -T,y61 -T,y62 -T,y63 -T,y64 -T,y65 -T,y66 -T,y67 -T,y68 -T,y69 -T,\n",
    "      y70 -T,y71 -T,y72 -T,y73 -T,y74 -T,y75 -T,y76 -T,y77 -T,y78 -T,y79 -T,\n",
    "      y80 -T,y81 -T,y82 -T,y83 -T,y84 -T,y85 -T,y86 -T,y87 -T,y88 -T,y89 -T]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "   # K = [y0 -T,y1 -T,y2 -T,y3 -T,y4 -T,y5 -T,y6 -T,y7 -T,y8 -T,y9 -T,y10 -T,y11 -T,y12 -T,y13 -T,y14 -T,y15 -T,y16 -T,y17 -T,y18 -T,y19 -T,y20 -T,y21 -T,y22 -T,y23 -T,y24 -T,y25 -T,y26 -T,y27 -T,y28 -T,y29 -T,y30 -T,y31 -T,y32 -T,y33 -T,y34 -T,y35 -T,y36 -T,y37 -T,y38 -T,y39 -T,y40 -T,y41 -T,y42 -T,y43 -T,y44 -T,y45 -T,y46 -T,y47 -T,y48 -T,y49 -T,y50 -T,y51 -T,y52 -T,y53 -T,y54 -T,y55 -T,y56 -T,y57 -T,y58 -T,y59 -T,y60 -T,y61 -T,y62 -T,y63 -T,y64 -T,y65 -T,y66 -T,y67 -T,y68 -T,y69 -T,y70 -T,y71 -T,y72 -T,y73 -T,y74 -T,y75 -T,y76 -T,y77 -T,y78 -T,y79 -T,y80 -T,y81 -T,y82 -T,y83 -T,y84 -T,y85 -T,y86 -T,y87 -T,y88 -T,y89 -T,y90 -T,y91 -T,y92 -T,y93 -T,y94 -T,y95 -T,y96 -T,y97 -T,y98 -T,y99 -T,y100 -T,y101 -T,y102 -T,y103 -T,y104 -T,y105 -T,y106 -T,y107 -T,y108 -T,y109 -T,y110 -T,y111 -T,y112 -T,y113 -T,y114 -T,y115 -T,y116 -T,y117 -T,y118 -T,y119 -T,y120 -T,y121 -T,y122 -T,y123 -T,y124 -T,y125 -T,y126 -T,y127 -T,y128 -T,y129 -T,y130 -T,y131 -T,y132 -T,y133 -T,y134 -T,y135 -T,y136 -T,y137 -T,y138 -T,y139 -T,y140 -T,y141 -T,y142 -T,y143 -T,y144 -T,y145 -T,y146 -T,y147 -T,y148 -T,y149 -T]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot([E])                               #plot 1st graph\n",
    "plt.plot([0,90],[T,T])                      #plot 2nd graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                        #find intersection on two graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
